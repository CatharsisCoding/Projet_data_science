{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91f63878",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "spark = SparkSession.builder.config(\"spark.driver.host\",\"localhost\").master(\"local[*]\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f7c26cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\" , \"true\").csv(\"InputTrain.csv\")\n",
    "label = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\" , \"true\").csv(\"StepOne_LabelTrain.csv\")\n",
    "test = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\" , \"true\").csv(\"InputTest.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "590ec104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_label = data.join(label,[\"index\",\"House_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2041e729",
   "metadata": {},
   "source": [
    "## Gradient Booster Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb105fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import GBTClassifier\n",
    "from pyspark.ml.regression import GBTRegressor\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator,BinaryClassificationEvaluator\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import IndexToString, StringIndexer, VectorIndexer\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8f3555d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = data.drop('index','House_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9fd4756",
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=data.drop(\"Index\",\"House_id\").columns, outputCol='features')\n",
    "data_T = assembler.transform(data)\n",
    "test_T = assembler.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64329e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            features|\n",
      "+--------------------+\n",
      "|[180.0,180.0,180....|\n",
      "|[2437.0,2426.0,21...|\n",
      "|[232.0,232.0,232....|\n",
      "|[180.333333333333...|\n",
      "|[344.0,341.0,341....|\n",
      "|[232.0,235.0,235....|\n",
      "|[193.0,190.0,190....|\n",
      "|[189.333333333333...|\n",
      "|[188.666666666666...|\n",
      "|[209.0,210.0,210....|\n",
      "|[193.0,191.0,191....|\n",
      "|[192.0,191.0,190....|\n",
      "|[586.333333333333...|\n",
      "|[183.0,181.0,181....|\n",
      "|[180.333333333333...|\n",
      "|[350.333333333333...|\n",
      "|[181.333333333333...|\n",
      "|[181.0,184.0,183....|\n",
      "|[182.0,182.0,182....|\n",
      "|[182.0,182.0,181....|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_TT = data_T.select(\"features\")\n",
    "data_TT.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "029292be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            features|\n",
      "+--------------------+\n",
      "|[595.0,595.0,601....|\n",
      "|[2682.66666666666...|\n",
      "|[529.0,534.0,540....|\n",
      "|[197.5,197.5,198....|\n",
      "|[291.5,285.0,283....|\n",
      "|[121.0,121.0,119....|\n",
      "|[656.5,653.0,653....|\n",
      "|[126.666666666666...|\n",
      "|[323.0,322.0,324....|\n",
      "|[119.0,118.0,118....|\n",
      "|[531.333333333333...|\n",
      "|[421.333333333333...|\n",
      "|[2668.5,2677.0,26...|\n",
      "|[118.0,118.0,118....|\n",
      "|[215.0,211.0,211....|\n",
      "|[198.0,198.0,195....|\n",
      "|[359.0,357.0,367....|\n",
      "|[220.0,211.0,211....|\n",
      "|[1223.33333333333...|\n",
      "|[2796.0,2793.0,28...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_TT = test_T.select(\"features\")\n",
    "test_TT.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666fc389",
   "metadata": {},
   "source": [
    "####  Washing Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b6795665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------+\n",
      "|            features|Washing Machine|\n",
      "+--------------------+---------------+\n",
      "|[180.0,180.0,180....|              0|\n",
      "|[2437.0,2426.0,21...|              0|\n",
      "|[232.0,232.0,232....|              0|\n",
      "|[180.333333333333...|              0|\n",
      "|[344.0,341.0,341....|              0|\n",
      "+--------------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train dataset\n",
    "train_WM = data_T.select('Index','features')\n",
    "label_WM = label.select('Index','Washing Machine')\n",
    "train_WM = train_WM.join(label_WM,\"Index\").drop('index')\n",
    "train_WM.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c6cea6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_WM = test_T.select('Index','features')\n",
    "# test_WM.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c3cd69f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------+\n",
      "|            features|Washing Machine|\n",
      "+--------------------+---------------+\n",
      "|[145.0,149.0,149....|              0|\n",
      "|[148.0,147.0,152....|              0|\n",
      "|[148.0,147.666666...|              0|\n",
      "|[149.0,147.0,149....|              0|\n",
      "|[149.0,148.5,149....|              0|\n",
      "|[149.0,149.0,150....|              0|\n",
      "|[149.0,150.0,149....|              0|\n",
      "|[149.0,152.0,148....|              0|\n",
      "|[149.0,152.0,150....|              0|\n",
      "|[149.0,176.333333...|              0|\n",
      "|[149.5,148.5,148....|              0|\n",
      "|[150.0,148.0,148....|              0|\n",
      "|[150.0,150.0,149....|              0|\n",
      "|[150.0,150.0,150....|              0|\n",
      "|[150.0,150.333333...|              0|\n",
      "|[150.0,151.0,150....|              0|\n",
      "|[150.0,151.666666...|              0|\n",
      "|[151.0,145.0,148....|              0|\n",
      "|[151.0,147.0,152....|              0|\n",
      "|[151.0,148.0,151....|              1|\n",
      "+--------------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+----------+--------------------+\n",
      "|prediction|            features|\n",
      "+----------+--------------------+\n",
      "|       0.0|[146.0,147.0,148....|\n",
      "|       0.0|[149.0,149.0,151....|\n",
      "|       0.0|[149.0,150.0,147....|\n",
      "|       0.0|[149.0,150.0,149....|\n",
      "|       0.0|[150.0,150.0,149....|\n",
      "+----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Test Error = 0.190104 \n"
     ]
    }
   ],
   "source": [
    "# Index labels, adding metadata to the label column.\n",
    "# Fit on whole dataset to include all labels in index.\n",
    "#More specifically: \n",
    "#StringIndexer maps a string column of labels to an ML column of label indices. If the input column is \n",
    "#numeric, we cast it to string and index the string values. The indices are in [0, numLabels). \n",
    "# Automatically identify categorical features, and index them.\n",
    "# We specify maxCategories so features with > 4 distinct values are treated as continuous.\n",
    "featureIndexer_WM =\\\n",
    "    VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures_WM\", maxCategories=4).fit(train_WM)\n",
    "\n",
    "# Split the data into training and test sets (30% held out for testing)\n",
    "#take a look to the function randomSplit()\n",
    "(trainingData, testData) = train_WM.randomSplit([0.7, 0.3])\n",
    "# Train a DecisionTree model. \n",
    "#take a look to DecisionTreeClassifier()\n",
    "trainingData.show()\n",
    "dt_WM = DecisionTreeClassifier(featuresCol='indexedFeatures_WM', labelCol='Washing Machine')\n",
    "\n",
    "# Chain indexers and tree in a Pipeline\n",
    "#Pipeline provide a uniform set of high-level APIs built on top of DataFrames that help \n",
    "#users create and tune practical machine learning pipelines.\n",
    "pipeline_WM = Pipeline(stages=[featureIndexer_WM, dt_WM])\n",
    "\n",
    "# Train model.  This also runs the indexers.\n",
    "model_WM = pipeline_WM.fit(trainingData)\n",
    "\n",
    "# Make predictions.\n",
    "predictions_WM = model_WM.transform(testData)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions_WM.select(\"prediction\", \"features\").show(5)\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "#Evaluator for Multiclass Classification, which expects input columns: prediction, label, \n",
    "#weight (optional) and probabilityCol (only for logLoss).\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"Washing Machine\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions_WM)\n",
    "print(\"Test Error = %g \" % (1.0 - accuracy))\n",
    "\n",
    "# #in the pipeline there are different stages, we want to print only the tree, so we will choose the 2nd stage\n",
    "# treeModel = model.stages[2] \n",
    "# # summary only\n",
    "# print(treeModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d47069",
   "metadata": {},
   "source": [
    "### Dishwasher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4a17fc9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+\n",
      "|            features|Dishwasher|\n",
      "+--------------------+----------+\n",
      "|[180.0,180.0,180....|         0|\n",
      "|[2437.0,2426.0,21...|         0|\n",
      "|[232.0,232.0,232....|         0|\n",
      "|[180.333333333333...|         0|\n",
      "|[344.0,341.0,341....|         0|\n",
      "+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_DW = data_T.select('Index','features')\n",
    "label_DW = label.select('Index','Dishwasher')\n",
    "train_DW = train_DW.join(label_DW,\"Index\").drop('Index')\n",
    "train_DW.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "43eddb75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+\n",
      "|            features|Dishwasher|\n",
      "+--------------------+----------+\n",
      "|[146.0,147.0,148....|         0|\n",
      "|[148.0,147.666666...|         0|\n",
      "|[149.0,147.0,149....|         0|\n",
      "|[149.0,148.5,149....|         0|\n",
      "|[149.0,149.0,150....|         0|\n",
      "|[149.0,149.0,151....|         0|\n",
      "|[149.0,150.0,147....|         0|\n",
      "|[149.0,150.0,149....|         0|\n",
      "|[149.0,150.0,149....|         0|\n",
      "|[149.0,152.0,148....|         0|\n",
      "|[149.0,152.0,150....|         0|\n",
      "|[149.5,148.5,148....|         0|\n",
      "|[150.0,148.0,148....|         0|\n",
      "|[150.0,150.0,149....|         0|\n",
      "|[150.0,150.0,152....|         0|\n",
      "|[150.0,151.0,149....|         0|\n",
      "|[150.0,151.0,150....|         0|\n",
      "|[150.0,151.5,152....|         0|\n",
      "|[150.333333333333...|         0|\n",
      "|[151.0,145.0,148....|         0|\n",
      "+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+----------+--------------------+\n",
      "|prediction|            features|\n",
      "+----------+--------------------+\n",
      "|       0.0|[145.0,149.0,149....|\n",
      "|       0.0|[148.0,147.0,152....|\n",
      "|       0.0|[149.0,176.333333...|\n",
      "|       0.0|[150.0,150.0,149....|\n",
      "|       0.0|[150.0,150.0,150....|\n",
      "+----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Test Error = 0.155099 \n"
     ]
    }
   ],
   "source": [
    "# Index labels, adding metadata to the label column.\n",
    "# Fit on whole dataset to include all labels in index.\n",
    "#More specifically: \n",
    "#StringIndexer maps a string column of labels to an ML column of label indices. If the input column is \n",
    "#numeric, we cast it to string and index the string values. The indices are in [0, numLabels). \n",
    "# Automatically identify categorical features, and index them.\n",
    "# We specify maxCategories so features with > 4 distinct values are treated as continuous.\n",
    "featureIndexer_DW =\\\n",
    "    VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures_DW\", maxCategories=4).fit(train_DW)\n",
    "\n",
    "# Split the data into training and test sets (30% held out for testing)\n",
    "#take a look to the function randomSplit()\n",
    "(trainingData, testData) = train_DW.randomSplit([0.7, 0.3])\n",
    "# Train a DecisionTree model. \n",
    "#take a look to DecisionTreeClassifier()\n",
    "trainingData.show()\n",
    "dt_DW = DecisionTreeClassifier(featuresCol='indexedFeatures_DW', labelCol='Dishwasher')\n",
    "\n",
    "# Chain indexers and tree in a Pipeline\n",
    "#Pipeline provide a uniform set of high-level APIs built on top of DataFrames that help \n",
    "#users create and tune practical machine learning pipelines.\n",
    "pipeline_DW = Pipeline(stages=[featureIndexer_DW, dt_DW])\n",
    "\n",
    "# Train model.  This also runs the indexers.\n",
    "model_DW = pipeline_DW.fit(trainingData)\n",
    "\n",
    "# Make predictions.\n",
    "predictions_DW = model_DW.transform(testData)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions_DW.select(\"prediction\", \"features\").show(5)\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "#Evaluator for Multiclass Classification, which expects input columns: prediction, label, \n",
    "#weight (optional) and probabilityCol (only for logLoss).\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"Dishwasher\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions_DW)\n",
    "print(\"Test Error = %g \" % (1.0 - accuracy))\n",
    "\n",
    "# #in the pipeline there are different stages, we want to print only the tree, so we will choose the 2nd stage\n",
    "# treeModel = model.stages[2] \n",
    "# # summary only\n",
    "# print(treeModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2151a2",
   "metadata": {},
   "source": [
    "### Microwave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "00f6d1a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+\n",
      "|            features|Microwave|\n",
      "+--------------------+---------+\n",
      "|[180.0,180.0,180....|        0|\n",
      "|[2437.0,2426.0,21...|        0|\n",
      "|[232.0,232.0,232....|        0|\n",
      "|[180.333333333333...|        0|\n",
      "|[344.0,341.0,341....|        0|\n",
      "+--------------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_MW = data_T.select('Index','features')\n",
    "label_MW = label.select('Index','Microwave')\n",
    "train_MW = train_MW.join(label_MW,\"Index\").drop('Index')\n",
    "train_MW.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cc687fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+\n",
      "|            features|Microwave|\n",
      "+--------------------+---------+\n",
      "|[146.0,147.0,148....|        0|\n",
      "|[148.0,147.0,152....|        0|\n",
      "|[149.0,147.0,149....|        0|\n",
      "|[149.0,149.0,150....|        0|\n",
      "|[149.0,149.0,151....|        0|\n",
      "|[149.0,150.0,147....|        0|\n",
      "|[149.0,150.0,149....|        0|\n",
      "|[149.0,152.0,148....|        0|\n",
      "|[149.0,176.333333...|        0|\n",
      "|[150.0,150.0,149....|        0|\n",
      "|[150.0,150.0,150....|        0|\n",
      "|[150.0,150.0,152....|        0|\n",
      "|[150.0,150.0,152....|        0|\n",
      "|[150.0,150.333333...|        0|\n",
      "|[150.0,151.0,149....|        0|\n",
      "|[150.0,151.0,150....|        0|\n",
      "|[150.0,151.5,152....|        0|\n",
      "|[150.0,151.666666...|        0|\n",
      "|[150.333333333333...|        0|\n",
      "|[151.0,148.0,151....|        0|\n",
      "+--------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+----------+--------------------+\n",
      "|prediction|            features|\n",
      "+----------+--------------------+\n",
      "|       0.0|[145.0,149.0,149....|\n",
      "|       0.0|[148.0,147.666666...|\n",
      "|       0.0|[149.0,148.5,149....|\n",
      "|       0.0|[149.0,150.0,149....|\n",
      "|       0.0|[149.0,152.0,150....|\n",
      "+----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Test Error = 0.170113 \n"
     ]
    }
   ],
   "source": [
    "# Index labels, adding metadata to the label column.\n",
    "# Fit on whole dataset to include all labels in index.\n",
    "#More specifically: \n",
    "#StringIndexer maps a string column of labels to an ML column of label indices. If the input column is \n",
    "#numeric, we cast it to string and index the string values. The indices are in [0, numLabels). \n",
    "# Automatically identify categorical features, and index them.\n",
    "# We specify maxCategories so features with > 4 distinct values are treated as continuous.\n",
    "featureIndexer_MW =\\\n",
    "    VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures_MW\", maxCategories=4).fit(train_MW)\n",
    "\n",
    "# Split the data into training and test sets (30% held out for testing)\n",
    "#take a look to the function randomSplit()\n",
    "(trainingData, testData) = train_MW.randomSplit([0.7, 0.3])\n",
    "# Train a DecisionTree model. \n",
    "#take a look to DecisionTreeClassifier()\n",
    "trainingData.show()\n",
    "dt_MW = DecisionTreeClassifier(featuresCol='indexedFeatures_MW', labelCol='Microwave')\n",
    "\n",
    "# Chain indexers and tree in a Pipeline\n",
    "#Pipeline provide a uniform set of high-level APIs built on top of DataFrames that help \n",
    "#users create and tune practical machine learning pipelines.\n",
    "pipeline_MW = Pipeline(stages=[featureIndexer_MW, dt_MW])\n",
    "\n",
    "# Train model.  This also runs the indexers.\n",
    "model_MW = pipeline_MW.fit(trainingData)\n",
    "\n",
    "# Make predictions.\n",
    "predictions_MW = model_MW.transform(testData)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions_MW.select(\"prediction\", \"features\").show(5)\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "#Evaluator for Multiclass Classification, which expects input columns: prediction, label, \n",
    "#weight (optional) and probabilityCol (only for logLoss).\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"Microwave\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions_MW)\n",
    "print(\"Test Error = %g \" % (1.0 - accuracy))\n",
    "\n",
    "# #in the pipeline there are different stages, we want to print only the tree, so we will choose the 2nd stage\n",
    "# treeModel = model.stages[2] \n",
    "# # summary only\n",
    "# print(treeModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8488791",
   "metadata": {},
   "source": [
    "### Kettle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2b20129e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|            features|Kettle|\n",
      "+--------------------+------+\n",
      "|[180.0,180.0,180....|     0|\n",
      "|[2437.0,2426.0,21...|     0|\n",
      "|[232.0,232.0,232....|     0|\n",
      "|[180.333333333333...|     0|\n",
      "|[344.0,341.0,341....|     0|\n",
      "+--------------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_K = data_T.select('Index','features')\n",
    "label_K = label.select('Index','Kettle')\n",
    "train_K = train_K.join(label_K,\"Index\").drop('Index')\n",
    "train_K.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "970b4ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|            features|Kettle|\n",
      "+--------------------+------+\n",
      "|[145.0,149.0,149....|     0|\n",
      "|[146.0,147.0,148....|     0|\n",
      "|[148.0,147.0,152....|     0|\n",
      "|[148.0,147.666666...|     0|\n",
      "|[149.0,147.0,149....|     0|\n",
      "|[149.0,148.5,149....|     0|\n",
      "|[149.0,149.0,150....|     0|\n",
      "|[149.0,149.0,151....|     0|\n",
      "|[149.0,150.0,149....|     0|\n",
      "|[149.0,150.0,149....|     0|\n",
      "|[149.0,152.0,150....|     0|\n",
      "|[149.0,176.333333...|     0|\n",
      "|[149.5,148.5,148....|     0|\n",
      "|[150.0,150.0,149....|     0|\n",
      "|[150.0,150.0,152....|     0|\n",
      "|[150.0,150.0,152....|     0|\n",
      "|[150.0,151.0,149....|     0|\n",
      "|[150.0,151.0,150....|     0|\n",
      "|[150.0,151.666666...|     0|\n",
      "|[150.333333333333...|     0|\n",
      "+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+----------+--------------------+\n",
      "|prediction|            features|\n",
      "+----------+--------------------+\n",
      "|       0.0|[149.0,150.0,147....|\n",
      "|       0.0|[149.0,152.0,148....|\n",
      "|       0.0|[150.0,148.0,148....|\n",
      "|       0.0|[150.0,150.0,149....|\n",
      "|       0.0|[150.0,150.0,150....|\n",
      "+----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Test Error = 0.232097 \n"
     ]
    }
   ],
   "source": [
    "# Index labels, adding metadata to the label column.\n",
    "# Fit on whole dataset to include all labels in index.\n",
    "#More specifically: \n",
    "#StringIndexer maps a string column of labels to an ML column of label indices. If the input column is \n",
    "#numeric, we cast it to string and index the string values. The indices are in [0, numLabels). \n",
    "# Automatically identify categorical features, and index them.\n",
    "# We specify maxCategories so features with > 4 distinct values are treated as continuous.\n",
    "featureIndexer_K =\\\n",
    "    VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures_K\", maxCategories=4).fit(train_K)\n",
    "\n",
    "# Split the data into training and test sets (30% held out for testing)\n",
    "#take a look to the function randomSplit()\n",
    "(trainingData, testData) = train_K.randomSplit([0.7, 0.3])\n",
    "# Train a DecisionTree model. \n",
    "#take a look to DecisionTreeClassifier()\n",
    "trainingData.show()\n",
    "dt_K = DecisionTreeClassifier(featuresCol='indexedFeatures_K', labelCol='Kettle')\n",
    "\n",
    "# Chain indexers and tree in a Pipeline\n",
    "#Pipeline provide a uniform set of high-level APIs built on top of DataFrames that help \n",
    "#users create and tune practical machine learning pipelines.\n",
    "pipeline_K = Pipeline(stages=[featureIndexer_K, dt_K])\n",
    "\n",
    "# Train model.  This also runs the indexers.\n",
    "model_K = pipeline_K.fit(trainingData)\n",
    "\n",
    "# Make predictions.\n",
    "predictions_K = model_K.transform(testData)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions_K.select(\"prediction\", \"features\").show(5)\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "#Evaluator for Multiclass Classification, which expects input columns: prediction, label, \n",
    "#weight (optional) and probabilityCol (only for logLoss).\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"Kettle\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions_K)\n",
    "print(\"Test Error = %g \" % (1.0 - accuracy))\n",
    "\n",
    "# #in the pipeline there are different stages, we want to print only the tree, so we will choose the 2nd stage\n",
    "# treeModel = model.stages[2] \n",
    "# # summary only\n",
    "# print(treeModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8f798c",
   "metadata": {},
   "source": [
    "### Tumble Dryer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "69f00986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+\n",
      "|            features|Tumble Dryer|\n",
      "+--------------------+------------+\n",
      "|[180.0,180.0,180....|           0|\n",
      "|[2437.0,2426.0,21...|           0|\n",
      "|[232.0,232.0,232....|           0|\n",
      "|[180.333333333333...|           0|\n",
      "|[344.0,341.0,341....|           0|\n",
      "+--------------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_TD = data_T.select('Index','features')\n",
    "label_TD = label.select('Index','Tumble Dryer')\n",
    "train_TD = train_TD.join(label_TD,\"Index\").drop('Index')\n",
    "train_TD.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4c5dcb7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+\n",
      "|            features|Tumble Dryer|\n",
      "+--------------------+------------+\n",
      "|[146.0,147.0,148....|           0|\n",
      "|[149.0,147.0,149....|           0|\n",
      "|[149.0,149.0,150....|           0|\n",
      "|[149.0,149.0,151....|           0|\n",
      "|[149.0,150.0,147....|           0|\n",
      "|[149.0,150.0,149....|           0|\n",
      "|[149.0,152.0,150....|           0|\n",
      "|[149.0,176.333333...|           0|\n",
      "|[149.5,148.5,148....|           0|\n",
      "|[150.0,150.0,149....|           0|\n",
      "|[150.0,150.0,149....|           0|\n",
      "|[150.0,150.0,150....|           0|\n",
      "|[150.0,150.0,152....|           0|\n",
      "|[150.0,150.0,152....|           0|\n",
      "|[150.0,151.0,149....|           0|\n",
      "|[150.0,151.0,150....|           0|\n",
      "|[150.0,151.5,152....|           0|\n",
      "|[150.0,151.666666...|           0|\n",
      "|[150.333333333333...|           0|\n",
      "|[150.5,151.0,152....|           0|\n",
      "+--------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+----------+--------------------+\n",
      "|prediction|            features|\n",
      "+----------+--------------------+\n",
      "|       0.0|[145.0,149.0,149....|\n",
      "|       0.0|[148.0,147.0,152....|\n",
      "|       0.0|[148.0,147.666666...|\n",
      "|       0.0|[149.0,148.5,149....|\n",
      "|       0.0|[149.0,150.0,149....|\n",
      "+----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Test Error = 0.0470289 \n"
     ]
    }
   ],
   "source": [
    "# Index labels, adding metadata to the label column.\n",
    "# Fit on whole dataset to include all labels in index.\n",
    "#More specifically: \n",
    "#StringIndexer maps a string column of labels to an ML column of label indices. If the input column is \n",
    "#numeric, we cast it to string and index the string values. The indices are in [0, numLabels). \n",
    "# Automatically identify categorical features, and index them.\n",
    "# We specify maxCategories so features with > 4 distinct values are treated as continuous.\n",
    "featureIndexer_TD =\\\n",
    "    VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures_TD\", maxCategories=4).fit(train_TD)\n",
    "\n",
    "# Split the data into training and test sets (30% held out for testing)\n",
    "#take a look to the function randomSplit()\n",
    "(trainingData, testData) = train_TD.randomSplit([0.7, 0.3])\n",
    "# Train a DecisionTree model. \n",
    "#take a look to DecisionTreeClassifier()\n",
    "trainingData.show()\n",
    "dt_TD = DecisionTreeClassifier(featuresCol='indexedFeatures_TD', labelCol='Tumble Dryer')\n",
    "\n",
    "# Chain indexers and tree in a Pipeline\n",
    "#Pipeline provide a uniform set of high-level APIs built on top of DataFrames that help \n",
    "#users create and tune practical machine learning pipelines.\n",
    "pipeline_TD = Pipeline(stages=[featureIndexer_TD, dt_TD])\n",
    "\n",
    "# Train model.  This also runs the indexers.\n",
    "model_TD = pipeline_TD.fit(trainingData)\n",
    "\n",
    "# Make predictions.\n",
    "predictions_TD = model_TD.transform(testData)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions_TD.select(\"prediction\", \"features\").show(5)\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "#Evaluator for Multiclass Classification, which expects input columns: prediction, label, \n",
    "#weight (optional) and probabilityCol (only for logLoss).\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"Tumble Dryer\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions_TD)\n",
    "print(\"Test Error = %g \" % (1.0 - accuracy))\n",
    "\n",
    "# #in the pipeline there are different stages, we want to print only the tree, so we will choose the 2nd stage\n",
    "# treeModel = model.stages[2] \n",
    "# # summary only\n",
    "# print(treeModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058c557c",
   "metadata": {},
   "source": [
    "## TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "78fbae73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7d1f94e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "WM = model_WM.transform(test_TT)\n",
    "DW = model_DW.transform(test_TT) \n",
    "MW = model_MW.transform(test_TT)\n",
    "K  = model_K.transform(test_TT)\n",
    "TD = model_TD.transform(test_TT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0787e64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "WM_v = WM.select(\"prediction\").collect()\n",
    "DW_v = DW.select(\"prediction\").collect()\n",
    "MW_v = MW.select(\"prediction\").collect()\n",
    "K_v  = K.select(\"prediction\").collect()\n",
    "TD_v = TD.select(\"prediction\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "45a54086",
   "metadata": {},
   "outputs": [],
   "source": [
    "WM_v = [i[0] for i in WM_v]\n",
    "DW_v = [i[0] for i in DW_v]\n",
    "MW_v = [i[0] for i in MW_v]\n",
    "K_v =  [i[0] for i in K_v]\n",
    "TD_v = [i[0] for i in TD_v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bf433fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "print(K_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4579dcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = np.zeros((len(WM_v), 5))\n",
    "results[:, 0] = WM_v\n",
    "results[:, 1] = DW_v\n",
    "results[:, 2] = TD_v\n",
    "results[:, 3] = MW_v\n",
    "results[:, 4] = K_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3c372b51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.unique(results,return_counts = True)\n",
    "inputes = pd.read_csv(\"./InputTest.csv\")\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3c1fa3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_res = pd.DataFrame(results.astype(int), columns=[\"Washing Machine\", \"Dishwasher\", \"Tumble Dryer\", \"Microwave\", \"Kettle\"])\n",
    "output_res.insert(0, \"Index\", inputes[\"Index\"])\n",
    "output_res.to_csv(\"./Results5.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
